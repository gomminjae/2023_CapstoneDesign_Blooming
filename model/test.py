# -*- coding: utf-8 -*-
"""Test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13xD8tFZ85y_rGmjVaGQqP-vvxavvM0gQ
"""

from google.colab import drive
drive.mount('/content/drive')

import os, glob
import scipy
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.utils import load_img
from keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input
from keras.layers import GlobalAveragePooling2D, Dense
from keras.models import Model, load_model
from keras.callbacks import ModelCheckpoint

!apt-get -qq install -y libarchive-dev && pip install -U libarchive
import libarchive
!apt-get -qq install -y graphviz && pip install pydot
import pydot
!pip install keras --upgrade
!pip install matplotlib-venn
!apt-get -qq install -y libfluidsynth1

from tensorflow.keras.preprocessing.image import img_to_array
import cv2
import matplotlib.pyplot as plt
import os
import glob
filepath='/content/drive/MyDrive/data/data/'
os.chdir(filepath)
full_list=glob.glob('Full/*.jpg')
free_list=glob.glob('Free/*.jpg')
print(len(full_list))
print(len(free_list))
full_img = img_to_array(load_img(full_list[0]), dtype=np.uint8)
free_img = img_to_array(load_img(free_list[0]), dtype=np.uint8)

from keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
    rotation_range=10,
    width_shift_range=0.1,
    height_shift_range=0.1,
    brightness_range=[0.8, 1.2],
    shear_range=0.01,
    zoom_range=[0.9, 1.1],
    validation_split=0.1,
    preprocessing_function=preprocess_input
)

val_datagen = ImageDataGenerator(
    validation_split=0.1,
    preprocessing_function=preprocess_input
)

train_gen = train_datagen.flow_from_directory(
    filepath,
    target_size=(224, 224),
    classes=['Full', 'Free'],
    class_mode='categorical',
    batch_size=32,
    shuffle=True,
    subset='training'
)

val_gen = val_datagen.flow_from_directory(
    filepath,
    target_size=(224, 224),
    classes=['Full', 'Free'],
    class_mode='categorical',
    batch_size=32,
    shuffle=False,
    subset='validation'
)

print(val_gen.class_indices)

model = load_model('model.h5')

last_weight = model.layers[-1].get_weights()[0] 
   
new_model = Model(
    inputs=model.input,
    outputs=(
        model.layers[-3].output,
        model.layers[-1].output
    )
)

new_model.summary()

test_img = img_to_array(load_img(os.path.join(filepath, 'Free/img_815061601.jpg'), target_size=(224, 224)))

test_input = preprocess_input(np.expand_dims(test_img.copy(), axis=0))

pred = model.predict(test_input)

plt.figure(figsize=(8, 8))
plt.title('%.2f%% Free' % (pred[0][1] * 100))
plt.imshow(test_img.astype(np.uint8))

last_conv_output, pred = new_model.predict(test_input)

last_conv_output = np.squeeze(last_conv_output) 
feature_activation_maps = scipy.ndimage.zoom(last_conv_output, (32, 32, 1), order=1) 
pred_class = np.argmax(pred) 
predicted_class_weights = last_weight[:, pred_class] 

final_output = np.dot(feature_activation_maps.reshape((224*224, 1280)), predicted_class_weights).reshape((224, 224)) # (224*224, 1280) dot_product (1280, 1) = (224*224, 1)

plt.imshow(final_output, cmap='jet')

fig, ax = plt.subplots(nrows=1, ncols=2)
fig.set_size_inches(16, 20)

ax[0].imshow(test_img.astype(np.uint8))
ax[0].set_title('image')
ax[0].axis('off')

ax[1].imshow(test_img.astype(np.uint8), alpha=0.5)
ax[1].imshow(final_output, cmap='jet', alpha=0.5)
ax[1].set_title('class activation map')
ax[1].axis('off')
plt.show()
print("안녕")
